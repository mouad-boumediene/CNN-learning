{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spoken Digit Recognition Youtube.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNE1hRWj/LIgsC9z+wGzbSs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mouad-boumediene/CNN-learning/blob/main/Spoken_Digit_Recognition_Youtube.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2OefusNTf_o"
      },
      "source": [
        "#ad the dataset\n",
        "!wget https://github.com/Jakobovski/free-spoken-digit-dataset/archive/refs/heads/master.zip\n",
        "#unzip the dataset folder\n",
        "! unzip master.zip \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47nbxObpa2lH"
      },
      "source": [
        "#\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from matplotlib import pyplot as plt\n",
        "import scipy.io.wavfile as wav\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.utils.np_utils import to_categorical\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atc0NQMPa811"
      },
      "source": [
        "def wav_to_spectrogram(audio_path, save_path, spectrogram_dimensions=(64, 64), noverlap=16, cmap='gray_r'):\n",
        "  sample_rate, samples = wav.read(audio_path)\n",
        "  fig = plt.figure()\n",
        "  fig.set_size_inches((spectrogram_dimensions[0]/fig.get_dpi(), spectrogram_dimensions[1]/fig.get_dpi()))\n",
        "  ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "  ax.set_axis_off()\n",
        "  fig.add_axes(ax)\n",
        "  ax.specgram(samples, cmap=cmap, Fs=2, noverlap=noverlap)\n",
        "  ax.xaxis.set_major_locator(plt.NullLocator())\n",
        "  ax.yaxis.set_major_locator(plt.NullLocator())\n",
        "  fig.savefig(save_path, bbox_inches=\"tight\", pad_inches=0)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwZkXychbGEB"
      },
      "source": [
        "#\n",
        "def dir_to_spectrogram(audio_dir, spectrogram_dir, spectrogram_dimensions=(64, 64), noverlap=16, cmap='gray_r'):\n",
        "  file_names = [f for f in listdir(audio_dir) if isfile(join(audio_dir, f)) and '.wav' in f]\n",
        "  for file_name in file_names:\n",
        "    print(file_name)\n",
        "    audio_path = audio_dir + file_name\n",
        "    spectogram_path = spectrogram_dir + file_name.replace('.wav', '.png')\n",
        "    wav_to_spectrogram(audio_path, spectogram_path, spectrogram_dimensions=spectrogram_dimensions, noverlap=noverlap, cmap=cmap)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA0f97s3dkYn"
      },
      "source": [
        "audio_folder = \"recordings/\"\n",
        "spectrogram_folder = \"spectrograms/\"\n",
        "dir_to_spectrogram(audio_folder, spectrogram_folder)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PFyceR8dmZ5"
      },
      "source": [
        "#\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "from keras.utils.np_utils import to_categorical\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDCf0Z50ggdN"
      },
      "source": [
        "imagesDir = \"spectrograms/\"\n",
        "trainset = []\n",
        "testset = []\n",
        "for file in os.listdir(imagesDir):\n",
        "  label = file.split('_')[0]\n",
        "  sample_number = file.split('_')[2]\n",
        "  img = image.load_img(imagesDir+file)\n",
        "  if sample_number in ['0.png','1.png','2.png','3.png','4.png']:\n",
        "    testset.append([image.img_to_array(img), label])\n",
        "  else:\n",
        "    trainset.append([image.img_to_array(img), label])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHQW9ZAOi5p9"
      },
      "source": [
        "#\n",
        "# Get only images in the train list not the Labels\n",
        "X_train = [item[0] for item in trainset]\n",
        "# Get only Labels in the train list not the images\n",
        "y_train = [item[1] for item in trainset]\n",
        "# Get only images in the test list not the Labels\n",
        "X_test = [item[0] for item in testset]\n",
        "# Get only Labels in the test list not the images\n",
        "y_test = [item[1] for item in testset]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blavgcmKjLne"
      },
      "source": [
        "# Convert list to numpy array in order to define input shape\n",
        "X_train = np.asanyarray(X_train)\n",
        "y_train = np.asanyarray(y_train)\n",
        "X_test = np.asanyarray(X_test)\n",
        "y_test = np.asanyarray(y_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SY8V8UHyq1Dk"
      },
      "source": [
        "# convert to one hot representation\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "#Normalize the images\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i0yWQhHlv8X"
      },
      "source": [
        "#N MODEL DESIGN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4aBfagrlxKD"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
        "from keras import models\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh4gQqUCl0Yb"
      },
      "source": [
        "data_shape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
        "def basic_cnn():\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=data_shape))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dropout(0.4))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer='Adadelta', metrics=['accuracy'])\n",
        "  return model\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IXNe4LOmCp0"
      },
      "source": [
        "#\n",
        "model0 = basic_cnn()\n",
        "model0.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NASbt9qqp2_4"
      },
      "source": [
        "model0.fit(X_train, y_train, batch_size = 50, validation_split=0.2, epochs = 100, verbose = 1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5y3q5a9vrtH6"
      },
      "source": [
        "model0.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agP3yM9g3tqD"
      },
      "source": [
        "!pip install pyyaml h5py  # Required to save models in HDF5 format\n",
        "model0.save(\"spoken_digit_recognition_.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2M7-Yh-G4GXC"
      },
      "source": [
        "index = 23\n",
        "print('ground Truth',np.argmax(y_test[index]))\n",
        "print('Prediction' ,np.argmax(model0.predict(X_test[index].reshape(1,64,64,3))))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}